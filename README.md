The application of artificial intelligence in social systems is improving, while AI prejudices that
are a part of models are a concern. Thus, utilizing the methods of systematic data analysis as well
as providing for the effective reduction of biases, the structure of the project enables addressing
these problems in full. The first one is bias in the training data or prejudiced algorithm which
favours prejudice or preconception Two of these have been evidenced in various ways. They can
lead to discrimination of some populations regarding demographic parameters, or try to preserve
the status of inequality in society.
Measures of combating bias in information processing increase the fairness of decision-making AI
on questions regarding social justice to promote diversity [4]. The objective of the project is to
employ EDA for addressing the large-scale data problem and identify biases in the given dataset
about the SDGs. After that, it is to organize such measures as data pre-processing and additional
adjustments to the algorithms and assess the effects of these interventions.
